{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Tensorflow and keras. \n",
    "I am doing this just to download the MNIST dataset available on keras. If you know any other way. feel free to do it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading data \n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Saving data in h5py format. \n",
    "with h5py.File('../data/train.h5', 'w') as f:\n",
    "    f['data'] = x_train / 255.0\n",
    "    f['label'] = y_train.reshape(-1, 1, 1, 1)\n",
    "\n",
    "with h5py.File('../data/test.h5', 'w') as f:\n",
    "   f['data'] = x_test / 255.0\n",
    "   f['label'] = y_test.reshape(-1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train_data', (60000, 1, 28, 28), (60000, 1, 1, 1))\n",
      "('test_data', (10000, 1, 28, 28), (10000, 1, 1, 1))\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"../data/train.h5\", \"r\")\n",
    "print(\"train_data\", f[\"data\"][:].shape, f[\"label\"][:].shape)\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = h5py.File(\"../data/test.h5\", \"r\")\n",
    "print(\"test_data\", f[\"data\"][:].shape, f[\"label\"][:].shape)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the caffe model using commandline . \n",
    "check \n",
    "- train_val.prototxt for model architecture code \n",
    "- train_solver.prototxt for model params \n",
    "\n",
    "Since I am using CPU, this will take time to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0615 05:10:39.983582    57 caffe.cpp:211] Use CPU.\n",
      "I0615 05:10:39.983964    57 solver.cpp:44] Initializing solver from parameters: \n",
      "test_iter: 100\n",
      "test_interval: 500\n",
      "base_lr: 0.001\n",
      "display: 500\n",
      "max_iter: 2000\n",
      "lr_policy: \"fixed\"\n",
      "momentum: 0.9\n",
      "snapshot: 500\n",
      "snapshot_prefix: \"./snapshot/lenet_mnist\"\n",
      "solver_mode: CPU\n",
      "net: \"./train_val.prototxt\"\n",
      "train_state {\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "momentum2: 0.999\n",
      "type: \"Adam\"\n",
      "I0615 05:10:39.986989    57 solver.cpp:87] Creating training net from net file: ./train_val.prototxt\n",
      "I0615 05:10:39.990631    57 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist\n",
      "I0615 05:10:39.990682    57 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
      "I0615 05:10:39.990782    57 net.cpp:51] Initializing net from parameters: \n",
      "name: \"LeNet\"\n",
      "state {\n",
      "  phase: TRAIN\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "layer {\n",
      "  name: \"mnist\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  hdf5_data_param {\n",
      "    source: \"./train_file_location.txt\"\n",
      "    batch_size: 100\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 20\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 50\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"ip1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 500\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0615 05:10:39.990864    57 layer_factory.hpp:77] Creating layer mnist\n",
      "I0615 05:10:39.990959    57 net.cpp:84] Creating Layer mnist\n",
      "I0615 05:10:39.990981    57 net.cpp:380] mnist -> data\n",
      "I0615 05:10:39.991008    57 net.cpp:380] mnist -> label\n",
      "I0615 05:10:39.991034    57 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: ./train_file_location.txt\n",
      "I0615 05:10:39.993849    57 hdf5_data_layer.cpp:94] Number of HDF5 files: 1\n",
      "I0615 05:10:40.111095    57 hdf5.cpp:32] Datatype class: H5T_FLOAT\n",
      "I0615 05:10:41.844584    57 hdf5.cpp:35] Datatype class: H5T_INTEGER\n",
      "I0615 05:10:41.846637    57 net.cpp:122] Setting up mnist\n",
      "I0615 05:10:41.846704    57 net.cpp:129] Top shape: 100 1 28 28 (78400)\n",
      "I0615 05:10:41.846751    57 net.cpp:129] Top shape: 100 1 1 1 (100)\n",
      "I0615 05:10:41.846803    57 net.cpp:137] Memory required for data: 314000\n",
      "I0615 05:10:41.846832    57 layer_factory.hpp:77] Creating layer conv1\n",
      "I0615 05:10:41.846901    57 net.cpp:84] Creating Layer conv1\n",
      "I0615 05:10:41.846949    57 net.cpp:406] conv1 <- data\n",
      "I0615 05:10:41.846987    57 net.cpp:380] conv1 -> conv1\n",
      "I0615 05:10:41.851013    57 net.cpp:122] Setting up conv1\n",
      "I0615 05:10:41.851102    57 net.cpp:129] Top shape: 100 20 24 24 (1152000)\n",
      "I0615 05:10:41.851117    57 net.cpp:137] Memory required for data: 4922000\n",
      "I0615 05:10:41.851163    57 layer_factory.hpp:77] Creating layer pool1\n",
      "I0615 05:10:41.851217    57 net.cpp:84] Creating Layer pool1\n",
      "I0615 05:10:41.851297    57 net.cpp:406] pool1 <- conv1\n",
      "I0615 05:10:41.851343    57 net.cpp:380] pool1 -> pool1\n",
      "I0615 05:10:41.851415    57 net.cpp:122] Setting up pool1\n",
      "I0615 05:10:41.851773    57 net.cpp:129] Top shape: 100 20 12 12 (288000)\n",
      "I0615 05:10:41.851794    57 net.cpp:137] Memory required for data: 6074000\n",
      "I0615 05:10:41.851831    57 layer_factory.hpp:77] Creating layer conv2\n",
      "I0615 05:10:41.851869    57 net.cpp:84] Creating Layer conv2\n",
      "I0615 05:10:41.851891    57 net.cpp:406] conv2 <- pool1\n",
      "I0615 05:10:41.852057    57 net.cpp:380] conv2 -> conv2\n",
      "I0615 05:10:41.852380    57 net.cpp:122] Setting up conv2\n",
      "I0615 05:10:41.852421    57 net.cpp:129] Top shape: 100 50 8 8 (320000)\n",
      "I0615 05:10:41.852439    57 net.cpp:137] Memory required for data: 7354000\n",
      "I0615 05:10:41.852484    57 layer_factory.hpp:77] Creating layer pool2\n",
      "I0615 05:10:41.852562    57 net.cpp:84] Creating Layer pool2\n",
      "I0615 05:10:41.852596    57 net.cpp:406] pool2 <- conv2\n",
      "I0615 05:10:41.852612    57 net.cpp:380] pool2 -> pool2\n",
      "I0615 05:10:41.852629    57 net.cpp:122] Setting up pool2\n",
      "I0615 05:10:41.852645    57 net.cpp:129] Top shape: 100 50 4 4 (80000)\n",
      "I0615 05:10:41.852665    57 net.cpp:137] Memory required for data: 7674000\n",
      "I0615 05:10:41.852682    57 layer_factory.hpp:77] Creating layer ip1\n",
      "I0615 05:10:41.852707    57 net.cpp:84] Creating Layer ip1\n",
      "I0615 05:10:41.852730    57 net.cpp:406] ip1 <- pool2\n",
      "I0615 05:10:41.852756    57 net.cpp:380] ip1 -> ip1\n",
      "I0615 05:10:41.857945    57 net.cpp:122] Setting up ip1\n",
      "I0615 05:10:41.858019    57 net.cpp:129] Top shape: 100 500 (50000)\n",
      "I0615 05:10:41.858037    57 net.cpp:137] Memory required for data: 7874000\n",
      "I0615 05:10:41.858068    57 layer_factory.hpp:77] Creating layer relu1\n",
      "I0615 05:10:41.858108    57 net.cpp:84] Creating Layer relu1\n",
      "I0615 05:10:41.858127    57 net.cpp:406] relu1 <- ip1\n",
      "I0615 05:10:41.858147    57 net.cpp:367] relu1 -> ip1 (in-place)\n",
      "I0615 05:10:41.858176    57 net.cpp:122] Setting up relu1\n",
      "I0615 05:10:41.858217    57 net.cpp:129] Top shape: 100 500 (50000)\n",
      "I0615 05:10:41.858245    57 net.cpp:137] Memory required for data: 8074000\n",
      "I0615 05:10:41.858263    57 layer_factory.hpp:77] Creating layer ip2\n",
      "I0615 05:10:41.858391    57 net.cpp:84] Creating Layer ip2\n",
      "I0615 05:10:41.858409    57 net.cpp:406] ip2 <- ip1\n",
      "I0615 05:10:41.858440    57 net.cpp:380] ip2 -> ip2\n",
      "I0615 05:10:41.858530    57 net.cpp:122] Setting up ip2\n",
      "I0615 05:10:41.858546    57 net.cpp:129] Top shape: 100 10 (1000)\n",
      "I0615 05:10:41.858559    57 net.cpp:137] Memory required for data: 8078000\n",
      "I0615 05:10:41.858574    57 layer_factory.hpp:77] Creating layer loss\n",
      "I0615 05:10:41.858592    57 net.cpp:84] Creating Layer loss\n",
      "I0615 05:10:41.858606    57 net.cpp:406] loss <- ip2\n",
      "I0615 05:10:41.858618    57 net.cpp:406] loss <- label\n",
      "I0615 05:10:41.858634    57 net.cpp:380] loss -> loss\n",
      "I0615 05:10:41.858701    57 layer_factory.hpp:77] Creating layer loss\n",
      "I0615 05:10:41.858750    57 net.cpp:122] Setting up loss\n",
      "I0615 05:10:41.858767    57 net.cpp:129] Top shape: (1)\n",
      "I0615 05:10:41.858779    57 net.cpp:132]     with loss weight 1\n",
      "I0615 05:10:41.858878    57 net.cpp:137] Memory required for data: 8078004\n",
      "I0615 05:10:41.858894    57 net.cpp:198] loss needs backward computation.\n",
      "I0615 05:10:41.858919    57 net.cpp:198] ip2 needs backward computation.\n",
      "I0615 05:10:41.858935    57 net.cpp:198] relu1 needs backward computation.\n",
      "I0615 05:10:41.858947    57 net.cpp:198] ip1 needs backward computation.\n",
      "I0615 05:10:41.858960    57 net.cpp:198] pool2 needs backward computation.\n",
      "I0615 05:10:41.858973    57 net.cpp:198] conv2 needs backward computation.\n",
      "I0615 05:10:41.858986    57 net.cpp:198] pool1 needs backward computation.\n",
      "I0615 05:10:41.858999    57 net.cpp:198] conv1 needs backward computation.\n",
      "I0615 05:10:41.859009    57 net.cpp:200] mnist does not need backward computation.\n",
      "I0615 05:10:41.859022    57 net.cpp:242] This network produces output loss\n",
      "I0615 05:10:41.859053    57 net.cpp:255] Network initialization done.\n",
      "I0615 05:10:41.861752    57 solver.cpp:172] Creating test net (#0) specified by net file: ./train_val.prototxt\n",
      "I0615 05:10:41.861830    57 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist\n",
      "I0615 05:10:41.862033    57 net.cpp:51] Initializing net from parameters: \n",
      "name: \"LeNet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"mnist\"\n",
      "  type: \"HDF5Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  hdf5_data_param {\n",
      "    source: \"./test_file_location.txt\"\n",
      "    batch_size: 100\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 20\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 50\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"ip1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"ip1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 500\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"ip2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"ip1\"\n",
      "  top: \"ip2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"ip2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0615 05:10:41.862234    57 layer_factory.hpp:77] Creating layer mnist\n",
      "I0615 05:10:41.862260    57 net.cpp:84] Creating Layer mnist\n",
      "I0615 05:10:41.862277    57 net.cpp:380] mnist -> data\n",
      "I0615 05:10:41.862295    57 net.cpp:380] mnist -> label\n",
      "I0615 05:10:41.862315    57 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: ./test_file_location.txt\n",
      "I0615 05:10:41.868072    57 hdf5_data_layer.cpp:94] Number of HDF5 files: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0615 05:10:42.179213    57 net.cpp:122] Setting up mnist\n",
      "I0615 05:10:42.179309    57 net.cpp:129] Top shape: 100 1 28 28 (78400)\n",
      "I0615 05:10:42.179342    57 net.cpp:129] Top shape: 100 1 1 1 (100)\n",
      "I0615 05:10:42.179356    57 net.cpp:137] Memory required for data: 314000\n",
      "I0615 05:10:42.179374    57 layer_factory.hpp:77] Creating layer label_mnist_1_split\n",
      "I0615 05:10:42.179396    57 net.cpp:84] Creating Layer label_mnist_1_split\n",
      "I0615 05:10:42.179409    57 net.cpp:406] label_mnist_1_split <- label\n",
      "I0615 05:10:42.179438    57 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0\n",
      "I0615 05:10:42.179509    57 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1\n",
      "I0615 05:10:42.179529    57 net.cpp:122] Setting up label_mnist_1_split\n",
      "I0615 05:10:42.179548    57 net.cpp:129] Top shape: 100 1 1 1 (100)\n",
      "I0615 05:10:42.179569    57 net.cpp:129] Top shape: 100 1 1 1 (100)\n",
      "I0615 05:10:42.179584    57 net.cpp:137] Memory required for data: 314800\n",
      "I0615 05:10:42.179677    57 layer_factory.hpp:77] Creating layer conv1\n",
      "I0615 05:10:42.179723    57 net.cpp:84] Creating Layer conv1\n",
      "I0615 05:10:42.179741    57 net.cpp:406] conv1 <- data\n",
      "I0615 05:10:42.179764    57 net.cpp:380] conv1 -> conv1\n",
      "I0615 05:10:42.179814    57 net.cpp:122] Setting up conv1\n",
      "I0615 05:10:42.179839    57 net.cpp:129] Top shape: 100 20 24 24 (1152000)\n",
      "I0615 05:10:42.179858    57 net.cpp:137] Memory required for data: 4922800\n",
      "I0615 05:10:42.179898    57 layer_factory.hpp:77] Creating layer pool1\n",
      "I0615 05:10:42.179953    57 net.cpp:84] Creating Layer pool1\n",
      "I0615 05:10:42.179970    57 net.cpp:406] pool1 <- conv1\n",
      "I0615 05:10:42.179986    57 net.cpp:380] pool1 -> pool1\n",
      "I0615 05:10:42.180007    57 net.cpp:122] Setting up pool1\n",
      "I0615 05:10:42.180024    57 net.cpp:129] Top shape: 100 20 12 12 (288000)\n",
      "I0615 05:10:42.180038    57 net.cpp:137] Memory required for data: 6074800\n",
      "I0615 05:10:42.180053    57 layer_factory.hpp:77] Creating layer conv2\n",
      "I0615 05:10:42.180096    57 net.cpp:84] Creating Layer conv2\n",
      "I0615 05:10:42.180130    57 net.cpp:406] conv2 <- pool1\n",
      "I0615 05:10:42.180143    57 net.cpp:380] conv2 -> conv2\n",
      "I0615 05:10:42.180424    57 net.cpp:122] Setting up conv2\n",
      "I0615 05:10:42.180496    57 net.cpp:129] Top shape: 100 50 8 8 (320000)\n",
      "I0615 05:10:42.180514    57 net.cpp:137] Memory required for data: 7354800\n",
      "I0615 05:10:42.180533    57 layer_factory.hpp:77] Creating layer pool2\n",
      "I0615 05:10:42.180552    57 net.cpp:84] Creating Layer pool2\n",
      "I0615 05:10:42.180567    57 net.cpp:406] pool2 <- conv2\n",
      "I0615 05:10:42.180583    57 net.cpp:380] pool2 -> pool2\n",
      "I0615 05:10:42.180603    57 net.cpp:122] Setting up pool2\n",
      "I0615 05:10:42.180615    57 net.cpp:129] Top shape: 100 50 4 4 (80000)\n",
      "I0615 05:10:42.180634    57 net.cpp:137] Memory required for data: 7674800\n",
      "I0615 05:10:42.180649    57 layer_factory.hpp:77] Creating layer ip1\n",
      "I0615 05:10:42.180667    57 net.cpp:84] Creating Layer ip1\n",
      "I0615 05:10:42.180681    57 net.cpp:406] ip1 <- pool2\n",
      "I0615 05:10:42.180697    57 net.cpp:380] ip1 -> ip1\n",
      "I0615 05:10:42.182816    57 net.cpp:122] Setting up ip1\n",
      "I0615 05:10:42.182864    57 net.cpp:129] Top shape: 100 500 (50000)\n",
      "I0615 05:10:42.182883    57 net.cpp:137] Memory required for data: 7874800\n",
      "I0615 05:10:42.182911    57 layer_factory.hpp:77] Creating layer relu1\n",
      "I0615 05:10:42.182925    57 net.cpp:84] Creating Layer relu1\n",
      "I0615 05:10:42.182942    57 net.cpp:406] relu1 <- ip1\n",
      "I0615 05:10:42.182965    57 net.cpp:367] relu1 -> ip1 (in-place)\n",
      "I0615 05:10:42.182981    57 net.cpp:122] Setting up relu1\n",
      "I0615 05:10:42.182996    57 net.cpp:129] Top shape: 100 500 (50000)\n",
      "I0615 05:10:42.183009    57 net.cpp:137] Memory required for data: 8074800\n",
      "I0615 05:10:42.183022    57 layer_factory.hpp:77] Creating layer ip2\n",
      "I0615 05:10:42.183039    57 net.cpp:84] Creating Layer ip2\n",
      "I0615 05:10:42.183053    57 net.cpp:406] ip2 <- ip1\n",
      "I0615 05:10:42.183069    57 net.cpp:380] ip2 -> ip2\n",
      "I0615 05:10:42.183111    57 net.cpp:122] Setting up ip2\n",
      "I0615 05:10:42.183135    57 net.cpp:129] Top shape: 100 10 (1000)\n",
      "I0615 05:10:42.183152    57 net.cpp:137] Memory required for data: 8078800\n",
      "I0615 05:10:42.183221    57 layer_factory.hpp:77] Creating layer ip2_ip2_0_split\n",
      "I0615 05:10:42.183239    57 net.cpp:84] Creating Layer ip2_ip2_0_split\n",
      "I0615 05:10:42.183254    57 net.cpp:406] ip2_ip2_0_split <- ip2\n",
      "I0615 05:10:42.183269    57 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0\n",
      "I0615 05:10:42.183285    57 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1\n",
      "I0615 05:10:42.183302    57 net.cpp:122] Setting up ip2_ip2_0_split\n",
      "I0615 05:10:42.183317    57 net.cpp:129] Top shape: 100 10 (1000)\n",
      "I0615 05:10:42.183328    57 net.cpp:129] Top shape: 100 10 (1000)\n",
      "I0615 05:10:42.183367    57 net.cpp:137] Memory required for data: 8086800\n",
      "I0615 05:10:42.183383    57 layer_factory.hpp:77] Creating layer accuracy\n",
      "I0615 05:10:42.183399    57 net.cpp:84] Creating Layer accuracy\n",
      "I0615 05:10:42.183413    57 net.cpp:406] accuracy <- ip2_ip2_0_split_0\n",
      "I0615 05:10:42.183429    57 net.cpp:406] accuracy <- label_mnist_1_split_0\n",
      "I0615 05:10:42.183444    57 net.cpp:380] accuracy -> accuracy\n",
      "I0615 05:10:42.183460    57 net.cpp:122] Setting up accuracy\n",
      "I0615 05:10:42.183475    57 net.cpp:129] Top shape: (1)\n",
      "I0615 05:10:42.183488    57 net.cpp:137] Memory required for data: 8086804\n",
      "I0615 05:10:42.183501    57 layer_factory.hpp:77] Creating layer loss\n",
      "I0615 05:10:42.183521    57 net.cpp:84] Creating Layer loss\n",
      "I0615 05:10:42.183534    57 net.cpp:406] loss <- ip2_ip2_0_split_1\n",
      "I0615 05:10:42.183548    57 net.cpp:406] loss <- label_mnist_1_split_1\n",
      "I0615 05:10:42.183569    57 net.cpp:380] loss -> loss\n",
      "I0615 05:10:42.183625    57 layer_factory.hpp:77] Creating layer loss\n",
      "I0615 05:10:42.183653    57 net.cpp:122] Setting up loss\n",
      "I0615 05:10:42.183668    57 net.cpp:129] Top shape: (1)\n",
      "I0615 05:10:42.183681    57 net.cpp:132]     with loss weight 1\n",
      "I0615 05:10:42.183712    57 net.cpp:137] Memory required for data: 8086808\n",
      "I0615 05:10:42.183745    57 net.cpp:198] loss needs backward computation.\n",
      "I0615 05:10:42.183760    57 net.cpp:200] accuracy does not need backward computation.\n",
      "I0615 05:10:42.183774    57 net.cpp:198] ip2_ip2_0_split needs backward computation.\n",
      "I0615 05:10:42.183789    57 net.cpp:198] ip2 needs backward computation.\n",
      "I0615 05:10:42.183801    57 net.cpp:198] relu1 needs backward computation.\n",
      "I0615 05:10:42.183815    57 net.cpp:198] ip1 needs backward computation.\n",
      "I0615 05:10:42.183828    57 net.cpp:198] pool2 needs backward computation.\n",
      "I0615 05:10:42.183842    57 net.cpp:198] conv2 needs backward computation.\n",
      "I0615 05:10:42.183856    57 net.cpp:198] pool1 needs backward computation.\n",
      "I0615 05:10:42.183869    57 net.cpp:198] conv1 needs backward computation.\n",
      "I0615 05:10:42.183887    57 net.cpp:200] label_mnist_1_split does not need backward computation.\n",
      "I0615 05:10:42.183902    57 net.cpp:200] mnist does not need backward computation.\n",
      "I0615 05:10:42.183915    57 net.cpp:242] This network produces output accuracy\n",
      "I0615 05:10:42.183935    57 net.cpp:242] This network produces output loss\n",
      "I0615 05:10:42.183955    57 net.cpp:255] Network initialization done.\n",
      "I0615 05:10:42.184033    57 solver.cpp:56] Solver scaffolding done.\n",
      "I0615 05:10:42.184105    57 caffe.cpp:248] Starting Optimization\n",
      "I0615 05:10:42.184124    57 solver.cpp:272] Solving LeNet\n",
      "I0615 05:10:42.184137    57 solver.cpp:273] Learning Rate Policy: fixed\n",
      "I0615 05:10:42.184763    57 solver.cpp:330] Iteration 0, Testing net (#0)\n",
      "I0615 05:10:53.515621    57 solver.cpp:397]     Test net output #0: accuracy = 0.0863\n",
      "I0615 05:10:53.515703    57 solver.cpp:397]     Test net output #1: loss = 2.36234 (* 1 = 2.36234 loss)\n",
      "I0615 05:10:53.723314    57 solver.cpp:218] Iteration 0 (0 iter/s, 11.539s/500 iters), loss = 2.38315\n",
      "I0615 05:10:53.723383    57 solver.cpp:237]     Train net output #0: loss = 2.38315 (* 1 = 2.38315 loss)\n",
      "I0615 05:10:53.723399    57 sgd_solver.cpp:105] Iteration 0, lr = 0.001\n",
      "I0615 05:12:11.612725    57 solver.cpp:447] Snapshotting to binary proto file ./snapshot/lenet_mnist_iter_500.caffemodel\n",
      "I0615 05:12:11.759665    57 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/lenet_mnist_iter_500.solverstate\n",
      "I0615 05:12:12.009078    57 solver.cpp:330] Iteration 500, Testing net (#0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0615 05:12:17.728579    57 solver.cpp:397]     Test net output #0: accuracy = 0.9828\n",
      "I0615 05:12:17.728684    57 solver.cpp:397]     Test net output #1: loss = 0.0556638 (* 1 = 0.0556638 loss)\n",
      "I0615 05:12:17.849936    57 solver.cpp:218] Iteration 500 (5.94347 iter/s, 84.126s/500 iters), loss = 0.0230622\n",
      "I0615 05:12:17.850024    57 solver.cpp:237]     Train net output #0: loss = 0.0230623 (* 1 = 0.0230623 loss)\n",
      "I0615 05:12:17.850049    57 sgd_solver.cpp:105] Iteration 500, lr = 0.001\n",
      "I0615 05:13:32.680519    57 solver.cpp:447] Snapshotting to binary proto file ./snapshot/lenet_mnist_iter_1000.caffemodel\n",
      "I0615 05:13:32.777681    57 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/lenet_mnist_iter_1000.solverstate\n",
      "I0615 05:13:32.943800    57 solver.cpp:330] Iteration 1000, Testing net (#0)\n",
      "I0615 05:13:37.888893    57 solver.cpp:397]     Test net output #0: accuracy = 0.9854\n",
      "I0615 05:13:37.888972    57 solver.cpp:397]     Test net output #1: loss = 0.0482543 (* 1 = 0.0482543 loss)\n",
      "I0615 05:13:37.999279    57 solver.cpp:218] Iteration 1000 (6.23838 iter/s, 80.149s/500 iters), loss = 0.017434\n",
      "I0615 05:13:37.999358    57 solver.cpp:237]     Train net output #0: loss = 0.0174341 (* 1 = 0.0174341 loss)\n",
      "I0615 05:13:37.999372    57 sgd_solver.cpp:105] Iteration 1000, lr = 0.001\n",
      "I0615 05:14:54.358438    57 solver.cpp:447] Snapshotting to binary proto file ./snapshot/lenet_mnist_iter_1500.caffemodel\n",
      "I0615 05:14:54.437662    57 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/lenet_mnist_iter_1500.solverstate\n",
      "I0615 05:14:54.574745    57 solver.cpp:330] Iteration 1500, Testing net (#0)\n",
      "I0615 05:14:59.546583    57 solver.cpp:397]     Test net output #0: accuracy = 0.9873\n",
      "I0615 05:14:59.546670    57 solver.cpp:397]     Test net output #1: loss = 0.0397261 (* 1 = 0.0397261 loss)\n",
      "I0615 05:14:59.676519    57 solver.cpp:218] Iteration 1500 (6.12167 iter/s, 81.677s/500 iters), loss = 0.0590213\n",
      "I0615 05:14:59.676589    57 solver.cpp:237]     Train net output #0: loss = 0.0590213 (* 1 = 0.0590213 loss)\n",
      "I0615 05:14:59.676601    57 sgd_solver.cpp:105] Iteration 1500, lr = 0.001\n",
      "I0615 05:16:13.590692    57 solver.cpp:447] Snapshotting to binary proto file ./snapshot/lenet_mnist_iter_2000.caffemodel\n",
      "I0615 05:16:13.681324    57 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot/lenet_mnist_iter_2000.solverstate\n",
      "I0615 05:16:13.862747    57 solver.cpp:310] Iteration 2000, loss = 0.0676236\n",
      "I0615 05:16:13.862828    57 solver.cpp:330] Iteration 2000, Testing net (#0)\n",
      "I0615 05:16:18.531666    57 solver.cpp:397]     Test net output #0: accuracy = 0.9857\n",
      "I0615 05:16:18.531749    57 solver.cpp:397]     Test net output #1: loss = 0.0477827 (* 1 = 0.0477827 loss)\n",
      "I0615 05:16:18.531762    57 solver.cpp:315] Optimization Done.\n",
      "I0615 05:16:18.531787    57 caffe.cpp:259] Optimization Done.\n"
     ]
    }
   ],
   "source": [
    "!caffe train --solver=./train_solver.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important things to know.\n",
    "- when defining params in train_solver.prototxt, I have mentioned snapshot as 5000. this means there will be a weight file saved after every 5000 iterations. You need to check the logs of where the model has high validation accuracy and use it for deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./snapshot/lenet_mnist_iter_1500.caffemodel',\n",
       " './snapshot/lenet_mnist_iter_2000.solverstate',\n",
       " './snapshot/lenet_mnist_iter_500.solverstate',\n",
       " './snapshot/lenet_mnist_iter_1000.solverstate',\n",
       " './snapshot/readme.md',\n",
       " './snapshot/lenet_mnist_iter_1500.solverstate',\n",
       " './snapshot/lenet_mnist_iter_2000.caffemodel',\n",
       " './snapshot/lenet_mnist_iter_500.caffemodel',\n",
       " './snapshot/lenet_mnist_iter_1000.caffemodel']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob(\"./snapshot/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not open file ./snapshot/lenet_mnist_iter_2970.caffemodel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b44e9967e548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# start the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m## load the test file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/caffe/python/caffe/classifier.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_file, pretrained_file, image_dims, mean, input_scale, raw_scale, channel_swap)\u001b[0m\n\u001b[1;32m     24\u001b[0m                  \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                  channel_swap=None):\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# configure pre-processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not open file ./snapshot/lenet_mnist_iter_2970.caffemodel"
     ]
    }
   ],
   "source": [
    "import caffe \n",
    "\n",
    "# Define the location of model and weights \n",
    "model = \"./deploy.prototxt\"\n",
    "weights = \"./snapshot/lenet_mnist_iter_2000.caffemodel\"\n",
    "\n",
    "# start the classifier\n",
    "net = caffe.Classifier(model, weights)\n",
    "\n",
    "## load the test file \n",
    "f = h5py.File(\"../data/test.h5\", \"r\")\n",
    "print(\"test_data\", f[\"data\"][:].shape, f[\"label\"][:].shape)\n",
    "\n",
    "# Seperate the input and label data. \n",
    "data = f[\"data\"][:]\n",
    "actual_label = f[\"label\"][:]\n",
    "\n",
    "# reshape and print the actual label \n",
    "y_test = actual_label.reshape(-1)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict(data)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ..., 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred = np.argmax(pred, axis =1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_pred=y_pred, y_true=y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 971    0    0    0    0    1    3    2    2    1]\n",
      " [   0 1124    5    0    1    1    0    0    4    0]\n",
      " [   4    0  971    0    0   47    5    3    2    0]\n",
      " [   1    0    8  953    0   15    3    1   27    2]\n",
      " [   1    0    3    0  967    1    4    0    1    5]\n",
      " [   4    0   33    4    0  845    2    2    2    0]\n",
      " [   5    2   44    3    1    2  897    0    4    0]\n",
      " [   7    1    0    0    0   61    3  951    1    4]\n",
      " [   0    0    2    0    1    5    0    0  963    3]\n",
      " [   5    0    3    0    4    2    0    2   33  960]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
